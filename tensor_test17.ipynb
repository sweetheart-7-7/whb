{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.fill([4], 0.25)\n",
    "b = tf.fill([4], 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5, 0.5, 0.5, 0.5], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [0.25, 0.25, 0.25, 0.25] * [2., 2., 2., 2.] = [0.5, 0.5, 0.5, 0.5]\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.constant(1.)\n",
    "x = tf.constant(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只有将复合运算包到下面才能自动求导数\n",
    "with tf.GradientTape() as tape:\n",
    "    # 对非tf.Variable类的数据需要加入监控才能够训练\n",
    "    tape.watch([w])\n",
    "    y2 = x*w\n",
    "# 默认求一次导数后会释放显存计算的资源,默认只能求一次\n",
    "# grad1 = tape.gradient(y, [w])\n",
    "grad2 = tape.gradient(y2, [w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=2.0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch([w])\n",
    "    y2 = x*w\n",
    "# 将persistent参数设置为True可进行多次求导\n",
    "grad1 = tape.gradient(y, [w])\n",
    "grad2 = tape.gradient(y2, [w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([None], [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad1,grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(x)\n",
    "w = tf.Variable(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二阶求导\n",
    "with tf.GradientTape() as t1:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y = x * w + b\n",
    "    dy_dw, dy_db = t2.gradient(y,[w, b])\n",
    "d2y_dw2 = t1.gradient(dy_dw, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32) None\n"
     ]
    }
   ],
   "source": [
    "print(dy_dw,dy_db,d2y_dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE Gradient\n",
    "x = tf.random.normal([2, 4])\n",
    "w = tf.random.normal([4 ,3])\n",
    "b = tf.zeros([3])\n",
    "y = tf.constant([2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w, b])\n",
    "    prob = tf.nn.softmax(x@w+b, axis=1)\n",
    "    loss = tf.reduce_mean(tf.losses.MSE(tf.one_hot(y, depth=3), prob))\n",
    "grads = tape.gradient(loss, [w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0.06164198,  0.00467886, -0.06632083],\n",
       "       [ 0.02359621, -0.03324214,  0.00964593],\n",
       "       [ 0.05432683,  0.05197052, -0.10629735],\n",
       "       [ 0.13250771, -0.03988266, -0.09262505]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.08361635,  0.03119816,  0.05241819], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy gradient\n",
    "x = tf.random.normal([2, 4])\n",
    "w = tf.random.normal([4, 3])\n",
    "b = tf.zeros([3])\n",
    "y = tf.constant([2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w, b])\n",
    "    logits = x @ w + b\n",
    "    # from_logits=True设置soft_max + cross_entropy,并且进行了数值稳定处理 \n",
    "    loss = tf.reduce_mean(tf.losses.categorical_crossentropy(tf.one_hot(y, depth=3), logits, from_logits=True))\n",
    "grads = tape.gradient(loss, [w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       " array([[-0.26351568,  0.27256033, -0.00904462],\n",
       "        [-0.04631647,  0.181802  , -0.13548553],\n",
       "        [ 0.02050748,  0.0602363 , -0.08074378],\n",
       "        [ 0.19000828, -0.03584233, -0.15416594]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.189046  ,  0.33562157, -0.14657557], dtype=float32)>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0], grads[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 链式法则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(1.)\n",
    "w1 = tf.constant(2.)\n",
    "b1 = tf.constant(1.)\n",
    "w2 = tf.constant(2.)\n",
    "b2 = tf.constant(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch([w1, b1, w2, b2])\n",
    "    y1 = x * w1 + b1\n",
    "    y2 = y1 * w2 + b2\n",
    "dy2_dy1 = tape.gradient(y2, [y1])[0]\n",
    "dy1_dw1 = tape.gradient(y1, [w1])[0]\n",
    "dy2_dw1 = tape.gradient(y2, [w1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32) \n",
      " tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dy2_dy1*dy1_dw1,\"\\n\",dy2_dw1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
